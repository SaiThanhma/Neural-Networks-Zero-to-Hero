{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6db9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7effaded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tokenizer import CharTokenizer\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f87213e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.0\n",
      "59.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Read the file and split into sentences\n",
    "base_path = 'dataset'\n",
    "\n",
    "with open(f'{base_path}/vi_sents', encoding='utf-8') as f:\n",
    "    sentences = f.read().split('\\n')\n",
    "\n",
    "# Calculate lengths of each sentence\n",
    "sentence_lengths = [len(sentence) for sentence in sentences]\n",
    "\n",
    "# Calculate 95th percentile length\n",
    "percentile_95 = np.percentile(sentence_lengths, 95)\n",
    "\n",
    "print(percentile_95)\n",
    "\n",
    "\n",
    "with open(f'{base_path}/en_sents', encoding='utf-8') as f:\n",
    "    sentences = f.read().split('\\n')\n",
    "\n",
    "# Calculate lengths of each sentence\n",
    "sentence_lengths = [len(sentence) for sentence in sentences]\n",
    "\n",
    "# Calculate 95th percentile length\n",
    "percentile_95 = np.percentile(sentence_lengths, 95)\n",
    "\n",
    "print(percentile_95)\n",
    "\n",
    "# # Filter sentences - keep only those <= 95th percentile length\n",
    "# filtered_sentences = [sentence for sentence in sentences if len(sentence) <= percentile_95]\n",
    "\n",
    "# # If you want to save the filtered sentences back to a file\n",
    "# with open('filtered_file.txt', 'w', encoding='utf-8') as f:\n",
    "#     f.write('\\n'.join(filtered_sentences))\n",
    "\n",
    "# print(f\"95th percentile length: {percentile_95}\")\n",
    "# print(f\"Original number of sentences: {len(sentences)}\")\n",
    "# print(f\"Filtered number of sentences: {len(filtered_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20f311d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.manual_seed(1337)\n",
    "\n",
    "base_path = 'dataset'\n",
    "\n",
    "with open(f'{base_path}/vi_sents', encoding='utf-8') as f:\n",
    "    vi_sentences = f.read().split('\\n')\n",
    "\n",
    "with open(f'{base_path}/en_sents', encoding='utf-8') as f:\n",
    "    en_sentences = f.read().split('\\n')\n",
    "\n",
    "\n",
    "assert len(vi_sentences) == len(en_sentences), \"Files have different number of sentences\"\n",
    "\n",
    "vi_lengths = [len(s) for s in vi_sentences]\n",
    "en_lengths = [len(s) for s in en_sentences]\n",
    "vi_percentile_95 = np.percentile(vi_lengths, 95)\n",
    "en_percentile_95 = np.percentile(en_lengths, 95)\n",
    "\n",
    "\n",
    "filtered_pairs = [(vi, en) for vi, en, vi_len, en_len in zip(\n",
    "    vi_sentences, en_sentences, vi_lengths, en_lengths)\n",
    "    if vi_len <= vi_percentile_95 and en_len <= en_percentile_95\n",
    "]\n",
    "\n",
    "# Separate back into Vietnamese and English\n",
    "filtered_vi, filtered_en = zip(*filtered_pairs)\n",
    "\n",
    "# Join with newlines\n",
    "vi_text = '\\n'.join(filtered_vi)\n",
    "en_text = '\\n'.join(filtered_en)\n",
    "\n",
    "\n",
    "vi_chars = sorted(list(set(vi_text)))\n",
    "en_chars = sorted(list(set(en_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f30a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_padding = \"\\uE000\"\n",
    "token_start =  \"\\uE001\"\n",
    "token_end = \"\\uE002\"\n",
    "vi_chars = [token_padding, token_start, token_end] + vi_chars\n",
    "en_chars = [token_padding] + en_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc1e2473",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_vi_size = len(vi_chars)\n",
    "\n",
    "stoi_vi = { ch:i for i,ch in enumerate(vi_chars) }\n",
    "itos_vi = { i:ch for i,ch in enumerate(vi_chars) }\n",
    "\n",
    "encode_vi = lambda s: [stoi_vi[c] for c in s]\n",
    "decode_vi = lambda l: ''.join([itos_vi[i] for i in l])\n",
    "\n",
    "vocab_eng_size = len(en_chars)\n",
    "\n",
    "stoi_en = { ch:i for i,ch in enumerate(en_chars) }\n",
    "itos_en = { i:ch for i,ch in enumerate(en_chars) }\n",
    "\n",
    "encode_en = lambda s: [stoi_en[c] for c in s]\n",
    "decode_en = lambda l: ''.join([itos_en[i] for i in l])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b75de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "addToken = lambda text: \"\".join(f\"{token_start} {line} {token_end}\" for line in text.split(\"\\n\"))\n",
    "\n",
    "vi = encode_vi(addToken(vi_text))\n",
    "en = encode_en(en_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7545a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def create_data(tokenized, token_end, add_end, token_padding):    \n",
    "    sublists = []\n",
    "    current = []\n",
    "    for token in tokenized:\n",
    "        if token == token_end:\n",
    "            if current:\n",
    "                if add_end:\n",
    "                    current.append(token)\n",
    "                sublists.append(torch.tensor(current))\n",
    "                current = []\n",
    "        else:\n",
    "            current.append(token)\n",
    "    if current:\n",
    "        sublists.append(torch.tensor(current))\n",
    "    padded = pad_sequence(sublists, batch_first=True, padding_value=token_padding)\n",
    "    return padded\n",
    "\n",
    "data_viet = create_data(vi, stoi_vi[token_end], True, stoi_vi[token_padding])\n",
    "data_eng = create_data(en, stoi_en['\\n'], False, stoi_en[token_padding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706cbc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([237469, 66]), torch.Size([237469, 59]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_viet.shape, data_eng.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af4d7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 20000\n",
    "eval_iters = 100\n",
    "batch_size = 32\n",
    "lr = 1e-3\n",
    "emb_enc_size = 256\n",
    "emb_dec_size = 256\n",
    "num_heads = 3\n",
    "num_layers = 5\n",
    "eval_interval = 250\n",
    "qk_dim = 128\n",
    "\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b13d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * data_viet.shape[0])\n",
    "train_data = (data_eng[:n], data_viet[:n])\n",
    "val_data = (data_eng[n:], data_viet[n:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "471d17d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_loss(model):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            (X_eng, x_viet), Y = get_batch(split)\n",
    "            logits = model(X_eng, x_viet)\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            Y = Y.view(B*T)\n",
    "            loss = F.cross_entropy(logits, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    N, L2 = data[1].shape\n",
    "    ix = torch.randint(0, N, (batch_size,))\n",
    "    l1, l2 = data\n",
    "    x = (l1[ix].to(device),l2[ix, : L2 - 1].to(device))\n",
    "    y = l2[ix, 1 : L2].to(device)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "246c0d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input: I've never been better\n",
      "When: \"\" then:\" \"\n",
      "When: \" \" then:\"t\"\n",
      "When: \" t\" then:\"ô\"\n",
      "When: \" tô\" then:\"i\"\n",
      "When: \" tôi\" then:\" \"\n",
      "When: \" tôi \" then:\"c\"\n",
      "When: \" tôi c\" then:\"h\"\n",
      "When: \" tôi ch\" then:\"ư\"\n",
      "When: \" tôi chư\" then:\"a\"\n",
      "When: \" tôi chưa\" then:\" \"\n",
      "When: \" tôi chưa \" then:\"b\"\n",
      "When: \" tôi chưa b\" then:\"a\"\n",
      "When: \" tôi chưa ba\" then:\"o\"\n",
      "When: \" tôi chưa bao\" then:\" \"\n",
      "When: \" tôi chưa bao \" then:\"g\"\n",
      "When: \" tôi chưa bao g\" then:\"i\"\n",
      "When: \" tôi chưa bao gi\" then:\"ờ\"\n",
      "When: \" tôi chưa bao giờ\" then:\" \"\n",
      "When: \" tôi chưa bao giờ \" then:\"t\"\n",
      "When: \" tôi chưa bao giờ t\" then:\"ố\"\n",
      "When: \" tôi chưa bao giờ tố\" then:\"t\"\n",
      "When: \" tôi chưa bao giờ tốt\" then:\" \"\n",
      "When: \" tôi chưa bao giờ tốt \" then:\"h\"\n",
      "When: \" tôi chưa bao giờ tốt h\" then:\"ơ\"\n",
      "When: \" tôi chưa bao giờ tốt hơ\" then:\"n\"\n",
      "When: \" tôi chưa bao giờ tốt hơn\" then:\" \"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n",
      "When: \" tôi chưa bao giờ tốt hơn \" then:\"\"\n"
     ]
    }
   ],
   "source": [
    "(x_eng, x_viet), y = get_batch('train')\n",
    "print(f'Encoder input: {decode_en(x_eng[0].tolist())}')\n",
    "for i in range(len(decode_vi(x_viet[0].tolist()))):\n",
    "    print(f'When: \"{decode_vi(x_viet[0].tolist())[:i + 1]}\" then:\"{decode_vi(y[0].tolist())[i]}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d207945",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_dim, qk_dim, num_heads, context_size = None, dropout = 0.1): # context_size = None means not causal attention\n",
    "        super().__init__()\n",
    "\n",
    "        self.query = nn.Linear(in_dim, qk_dim * num_heads, bias=True)\n",
    "        self.key = nn.Linear(in_dim, qk_dim * num_heads, bias=True)\n",
    "        self.value = nn.Linear(in_dim, qk_dim * num_heads, bias=True)\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.context_size = context_size\n",
    "        \n",
    "        if self.context_size is not None:\n",
    "            self.register_buffer('att_mask', torch.triu(torch.ones((context_size, context_size)), diagonal= 1).bool())\n",
    "\n",
    "        self.proj = nn.Linear(qk_dim * num_heads, in_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T, _ = x.shape\n",
    "\n",
    "        queries = self.query(x) # (B, T, qk_dim * num_heads)\n",
    "        keys = self.key(x) # (B, T, qk_dim * num_heads)\n",
    "        values = self.value(x) # (B, T, qk_dim * num_heads)\n",
    "\n",
    "        queries = queries.reshape(B, T, self.num_heads, -1).transpose(1, 2) # (B, num_heads, T, qk_dim)\n",
    "        keys = keys.reshape(B, T, self.num_heads, -1).transpose(1, 2) # (B, num_heads, T, qk_dim)\n",
    "        values = values.reshape(B, T, self.num_heads, -1).transpose(1, 2) # (B, num_heads, T, qk_dim)\n",
    "\n",
    "        att = queries @ keys.transpose(2, 3) * queries.shape[3]**(-0.5) # (B, num_heads, T, T) = (B, num_heads, T, qk_dim) x (B, num_heads, qk_dim, T)\n",
    "        if self.context_size is not None:\n",
    "            att = att.masked_fill(self.att_mask[:T,:T], float(\"-inf\"))\n",
    "        att_norm = F.softmax(att, dim = 3) # (B, num_heads, T, T)\n",
    "        att_norm = self.dropout(att_norm)\n",
    "        v = att_norm @ values #  (B, num_heads, T, qk_dim) = (B, num_heads, T, T) x (B, num_heads, T, qk_dim)\n",
    "        v = v.transpose(1,2).reshape(B, T, -1)  # (B, T, qk_dim * num_heads)\n",
    "        out = self.dropout(self.proj(v)) # (B, T, in_dim)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, in_enc_dim, in_dec_dim, qk_dim, num_heads, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(in_dec_dim, qk_dim * num_heads, bias=True) # Check if bias is necessary\n",
    "        self.key = nn.Linear(in_enc_dim, qk_dim * num_heads, bias=True) # Check if bias is necessary\n",
    "        self.value = nn.Linear(in_enc_dim, qk_dim * num_heads, bias=True) # Check if bias is necessary\n",
    "        self.proj = nn.Linear(qk_dim * num_heads, in_dec_dim)\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x_enc, x_dec):\n",
    "        B,T_dec, _ = x_dec.shape\n",
    "        B,T_enc, _ = x_enc.shape\n",
    "\n",
    "        queries = self.query(x_dec) # (B, T, qk_dim * num_heads)\n",
    "        keys = self.key(x_enc) # (B, T, qk_dim * num_heads)\n",
    "        values = self.value(x_enc) # (B, T, qk_dim * num_heads)\n",
    "\n",
    "        queries = queries.reshape(B, T_dec, self.num_heads, -1).transpose(1,2) # (B, num_heads, T_dec, qk_dim)\n",
    "        keys = keys.reshape(B, T_enc, self.num_heads, -1).transpose(1,2) # (B, num_heads, T_enc, qk_dim)\n",
    "        values = values.reshape(B, T_enc, self.num_heads, -1).transpose(1,2) # (B, num_heads, T_enc, qk_dim)\n",
    "\n",
    "        att = queries @ keys.transpose(2, 3) * queries.shape[3]**(-0.5) # (B, num_heads, T_dec, T_enc) = (B, num_heads, T_dec, qk_dim) x (B, num_heads, qk_dim, T_enc)\n",
    "        att_norm = F.softmax(att, dim = 3) # (B, num_heads, T_dec, T_enc)\n",
    "        att_norm = self.dropout(att_norm)\n",
    "        v = att_norm @ values # (B, num_heads, T_dec, qk_dim) = (B, num_heads, T_dec, T_enc) x (B, num_heads, T_enc, qk_dim)\n",
    "        \n",
    "        v = v.transpose(1,2).reshape(B, T_dec, -1)  # (B, T_dec, num_heads * qk_dim)\n",
    "        out = self.dropout(self.proj(v))\n",
    "        return out\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, in_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        inner_dim = in_dim * 4\n",
    "        self.first = nn.Linear(in_dim, inner_dim, bias = True)\n",
    "        self.second = nn.Linear(inner_dim, in_dim, bias = True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.first(x))\n",
    "        x = self.second(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_dim, qk_dim, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.sa = SelfAttention(in_dim, qk_dim, num_heads, dropout = dropout)\n",
    "        self.ln1 = nn.LayerNorm(in_dim)\n",
    "        self.ffn = FeedForward(in_dim, dropout = dropout)\n",
    "        self.ln2 = nn.LayerNorm(in_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffn(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_enc_dim, in_dec_dim, qk_dim, num_heads, context_size, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.sa = SelfAttention(in_dec_dim, qk_dim, num_heads, context_size = context_size, dropout = dropout)\n",
    "        self.ln1 = nn.LayerNorm(in_dec_dim)\n",
    "        self.ca = CrossAttention(in_enc_dim, in_dec_dim, qk_dim, num_heads, dropout = dropout)\n",
    "        self.ln2 = nn.LayerNorm(in_dec_dim)\n",
    "        self.ffn = FeedForward(in_dec_dim, dropout = dropout)\n",
    "        self.ln3 = nn.LayerNorm(in_dec_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x_enc, x_dec):\n",
    "        x = x_dec + self.sa(self.ln1(x_dec))\n",
    "        x = x + self.ca(x_enc, self.ln2(x))\n",
    "        x = x + self.ffn(self.ln3(x))\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_enc_size, emb_enc_dim, context_enc_size, vocab_dec_size, emb_dec_dim, context_dec_size, qk_dim, num_heads, num_layers, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        assert num_layers > 0\n",
    "        self.emb_enc = nn.Embedding(vocab_enc_size, emb_enc_dim)\n",
    "        self.emb_dec = nn.Embedding(vocab_dec_size, emb_dec_dim)\n",
    "\n",
    "        self.encoders = nn.ModuleList([Encoder(emb_enc_dim, qk_dim, num_heads,  dropout = dropout) for _ in range(num_layers)])\n",
    "        self.decoders = nn.ModuleList([Decoder(emb_enc_dim, emb_dec_dim, qk_dim, num_heads, context_dec_size, dropout = dropout) for _ in range(num_layers)])\n",
    "        self.linear = nn.Linear(emb_dec_dim, vocab_dec_size)\n",
    "\n",
    "        self.register_buffer('pos_enc_emb', self.positional_encoding(emb_enc_dim, context_enc_size)) \n",
    "        self.register_buffer('pos_dec_emb', self.positional_encoding(emb_dec_dim, context_dec_size))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x_enc, x_dec):\n",
    "        x_enc_emb = self.dropout(self.emb_enc(x_enc) + self.pos_enc_emb[:x_enc.shape[1]]) # Broadcasting\n",
    "        x_dec_emb = self.dropout(self.emb_dec(x_dec) + self.pos_dec_emb[:x_dec.shape[1]]) # Broadcasting\n",
    "\n",
    "        for encoder in self.encoders:\n",
    "            x_enc_emb = encoder(x_enc_emb)\n",
    "            \n",
    "        for decoder in self.decoders:\n",
    "            x_dec_emb = decoder(x_enc_emb, x_dec_emb)\n",
    "\n",
    "        out = self.linear(x_dec_emb)\n",
    "        return out\n",
    "\n",
    "    def positional_encoding(self, in_dim, length):\n",
    "        pos = torch.arange(length)[:, None] # (length, 1)\n",
    "        i = torch.arange(in_dim)[None, :] # (1, in_dim)\n",
    "        #i = 10000 ** (i / in_dim)\n",
    "\n",
    "        angle_rates = 1 / torch.pow(10000, (2 * (i // 2)) / in_dim)\n",
    "        pe = pos * angle_rates  # (length, in_dim)\n",
    "\n",
    "        #pe = pos / i # (length, in_dim)\n",
    "        \n",
    "        pe[:, ::2] = torch.sin(pe[:, ::2])\n",
    "        pe[:, 1::2] = torch.cos(pe[:, 1::2])\n",
    "        return pe\n",
    "    \n",
    "    def generate(self, x_enc, start_token_id, end_token_id, max_length=64):\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            current = torch.tensor([[start_token_id]], device=x_enc.device)\n",
    "            \n",
    "            for _ in range(max_length):\n",
    "                logits = self(x_enc, current)  # (1, t, vocab_size)\n",
    "                logits = logits[:, -1, :]  # (1, vocab_size)\n",
    "                probs = F.softmax(logits, dim=1)  # (1, vocab_size)\n",
    "                next_token = torch.multinomial(probs, 1)  # (1, 1)\n",
    "                current = torch.cat((current, next_token), dim=1)\n",
    "                \n",
    "                if next_token.item() == end_token_id:\n",
    "                    break\n",
    "                    \n",
    "        return current\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3823a1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 104, 65, 59)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_dec_size, context_enc_size = data_viet.shape[1] - 1, data_eng.shape[1]\n",
    "vocab_vi_size, vocab_eng_size, context_dec_size, context_enc_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3370876",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = Transformer(vocab_eng_size, emb_enc_size, context_enc_size, vocab_vi_size, emb_dec_size, context_dec_size, qk_dim, num_heads, num_layers)\n",
    "tf.to(device)\n",
    "optimizer = torch.optim.AdamW(tf.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7178895a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 5.5342, val loss 5.5332\n",
      "step 250: train loss 0.8113, val loss 0.8030\n",
      "step 500: train loss 0.6959, val loss 0.6807\n",
      "step 750: train loss 0.6358, val loss 0.6324\n",
      "step 1000: train loss 0.5868, val loss 0.5985\n",
      "step 1250: train loss 0.5702, val loss 0.5799\n",
      "step 1500: train loss 0.5557, val loss 0.5626\n",
      "step 1750: train loss 0.5400, val loss 0.5330\n",
      "step 2000: train loss 0.5141, val loss 0.5320\n",
      "step 2250: train loss 0.5107, val loss 0.5140\n",
      "step 2500: train loss 0.4938, val loss 0.4983\n",
      "step 2750: train loss 0.4725, val loss 0.4867\n",
      "step 3000: train loss 0.4673, val loss 0.4685\n",
      "step 3250: train loss 0.4540, val loss 0.4651\n",
      "step 3500: train loss 0.4519, val loss 0.4472\n",
      "step 3750: train loss 0.4407, val loss 0.4477\n",
      "step 4000: train loss 0.4335, val loss 0.4313\n",
      "step 4250: train loss 0.4127, val loss 0.4126\n",
      "step 4500: train loss 0.4072, val loss 0.4184\n",
      "step 4750: train loss 0.4035, val loss 0.4136\n",
      "step 5000: train loss 0.3926, val loss 0.3899\n",
      "step 5250: train loss 0.3823, val loss 0.3857\n",
      "step 5500: train loss 0.3748, val loss 0.3785\n",
      "step 5750: train loss 0.3663, val loss 0.3799\n",
      "step 6000: train loss 0.3591, val loss 0.3608\n",
      "step 6250: train loss 0.3544, val loss 0.3599\n",
      "step 6500: train loss 0.3440, val loss 0.3604\n",
      "step 6750: train loss 0.3393, val loss 0.3517\n",
      "step 7000: train loss 0.3334, val loss 0.3466\n",
      "step 7250: train loss 0.3312, val loss 0.3427\n",
      "step 7500: train loss 0.3183, val loss 0.3274\n",
      "step 7750: train loss 0.3133, val loss 0.3257\n",
      "step 8000: train loss 0.3197, val loss 0.3222\n",
      "step 8250: train loss 0.3163, val loss 0.3245\n",
      "step 8500: train loss 0.3076, val loss 0.3188\n",
      "step 8750: train loss 0.3008, val loss 0.3086\n",
      "step 9000: train loss 0.3032, val loss 0.3116\n",
      "step 9250: train loss 0.2973, val loss 0.3060\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m % eval_interval == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28miter\u001b[39m == iterations - \u001b[32m1\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         losses_i = \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m         losses.append(losses_i)\n\u001b[32m      6\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28miter\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses_i[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, val loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses_i[\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mestimate_loss\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m     11\u001b[39m         Y = Y.view(B*T)\n\u001b[32m     12\u001b[39m         loss = F.cross_entropy(logits, Y)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m         losses[k] = \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     out[split] = losses.mean()\n\u001b[32m     15\u001b[39m model.train()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for iter in range(iterations):\n",
    "    if iter % eval_interval == 0 or iter == iterations - 1:\n",
    "        losses_i = estimate_loss(tf)\n",
    "        losses.append(losses_i)\n",
    "        print(f\"step {iter}: train loss {losses_i['train']:.4f}, val loss {losses_i['val']:.4f}\")\n",
    "        \n",
    "    (x_eng, x_viet), y = get_batch('train')\n",
    "    logits = tf(x_eng, x_viet)\n",
    "    B, T, C = logits.shape\n",
    "    logits = logits.view(B*T, C)\n",
    "    y = y.view(B*T)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b56c06bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    'epoch': iterations,\n",
    "    'state_dict': tf.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'losses': losses\n",
    "}\n",
    "torch.save(state, './model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16cd26ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chiếc xe thời gian. \n"
     ]
    }
   ],
   "source": [
    "input = 'The crowd went wild.\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000\\ue000'\n",
    "out = tf.generate(torch.tensor(encode_en(input))[None,:].to(device), stoi_vi[token_start], stoi_vi[token_end], 1000)\n",
    "#print(decode_vi(*out.tolist()))\n",
    "out = decode_vi(*out.tolist())\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b772644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
